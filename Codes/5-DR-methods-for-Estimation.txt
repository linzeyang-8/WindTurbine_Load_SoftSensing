import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from catboost import CatBoostRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from tabulate import tabulate


# Define Multi-Layer Perceptron model
class MLP(nn.Module):
    def __init__(self, input_size, hidden_sizes, dropout_rate):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_sizes[0])
        self.dropout1 = nn.Dropout(dropout_rate)
        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])
        self.prelu = nn.PReLU()
        self.dropout2 = nn.Dropout(dropout_rate)
        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])
        self.dropout3 = nn.Dropout(dropout_rate)
        self.fc4 = nn.Linear(hidden_sizes[2], 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.dropout1(x)
        x = self.fc2(x)
        x = self.prelu(x)
        x = self.dropout2(x)
        x = self.fc3(x)
        x = self.prelu(x)
        x = self.dropout3(x)
        x = self.fc4(x)
        return x


# Train MLP model
def train_mlp_model(mlp_model, X_train_tensor, y_train_tensor, hyperparameters):
    dataset = TensorDataset(X_train_tensor, y_train_tensor)
    loader = DataLoader(dataset, batch_size=hyperparameters['batch_size'], shuffle=True)
    optimizer = optim.AdamW(mlp_model.parameters(), lr=hyperparameters['lr'])
    criterion = nn.SmoothL1Loss()

    for epoch in range(hyperparameters['num_epochs']):
        mlp_model.train()
        running_loss = 0.0
        for batch_X, batch_y in loader:
            optimizer.zero_grad()
            outputs = mlp_model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(loader):.6f}')
    return mlp_model


# Evaluate model performance
def evaluate_model(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return mse, rmse, mae, r2


# Data standardization
def standardize_data(X_train, X_test):
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    return X_train_scaled, X_test_scaled


# Train and evaluate model (return validation and test set results simultaneously)
def train_and_evaluate(X_train, X_test, y_train, y_test, catboost_params, mlp_params):
    # Standardize data
    X_train_scaled, X_test_scaled = standardize_data(X_train, X_test)

    mse_scores = []  # Validation set MSE (3-fold)
    rmse_scores = []  # Validation set RMSE
    mae_scores = []   # Validation set MAE
    r2_scores = []    # Validation set R2
    test_r2_scores = []  # Test set R2 (individual 3-fold results)
    y_pred_test_list = []

    kf = KFold(n_splits=3, shuffle=True, random_state=42)

    for fold, (train_index, val_index) in enumerate(kf.split(X_train_scaled)):
        print(f'Processing fold {fold + 1}')

        # Split into training and validation sets
        X_train_fold = X_train_scaled[train_index]
        y_train_fold = y_train.iloc[train_index]
        X_val_fold = X_train_scaled[val_index]
        y_val_fold = y_train.iloc[val_index]

        # Train CatBoost model
        print('Training CatBoost model...')
        regressor = CatBoostRegressor(**catboost_params, verbose=0, random_state=42)
        regressor.fit(X_train_fold, y_train_fold)

        # Get CatBoost prediction results (as new features)
        catboost_pred_train = regressor.predict(X_train_fold).reshape(-1, 1)
        catboost_pred_val = regressor.predict(X_val_fold).reshape(-1, 1)
        catboost_pred_test = regressor.predict(X_test_scaled).reshape(-1, 1)

        # Concatenate new features
        X_train_new = np.hstack((X_train_fold, catboost_pred_train))
        X_val_new = np.hstack((X_val_fold, catboost_pred_val))
        X_test_new = np.hstack((X_test_scaled, catboost_pred_test))

        # Convert to tensors
        X_train_tensor = torch.tensor(X_train_new, dtype=torch.float32)
        y_train_tensor = torch.tensor(y_train_fold.values.reshape(-1, 1), dtype=torch.float32)
        X_val_tensor = torch.tensor(X_val_new, dtype=torch.float32)
        X_test_tensor = torch.tensor(X_test_new, dtype=torch.float32)

        torch.manual_seed(42)

        # Initialize and train MLP
        mlp_model = MLP(X_train_tensor.shape[1], mlp_params['MLP_hidden_sizes'], mlp_params['dropout_rate'])
        print('Training MLP model...')
        mlp_model = train_mlp_model(mlp_model, X_train_tensor, y_train_tensor, mlp_params)

        # Validate and test set prediction
        mlp_model.eval()
        with torch.no_grad():
            y_pred_val = mlp_model(X_val_tensor).numpy().flatten()
            y_pred_test = mlp_model(X_test_tensor).numpy().flatten()

        # Record validation set metrics
        mse, rmse, mae, r2 = evaluate_model(y_val_fold, y_pred_val)
        mse_scores.append(mse)
        rmse_scores.append(rmse)
        mae_scores.append(mae)
        r2_scores.append(r2)

        # Record test set single-fold metrics
        _, _, _, test_r2 = evaluate_model(y_test, y_pred_test)
        test_r2_scores.append(test_r2)
        y_pred_test_list.append(y_pred_test)

    # Average test set predictions
    y_pred_test_mean = np.mean(y_pred_test_list, axis=0)
    mse_test, rmse_test, mae_test, r2_test = evaluate_model(y_test, y_pred_test_mean)

    return {
        # Validation set metrics (3-fold mean ± standard deviation)
        'val_mse': (np.mean(mse_scores), np.std(mse_scores)),
        'val_rmse': (np.mean(rmse_scores), np.std(rmse_scores)),
        'val_mae': (np.mean(mae_scores), np.std(mae_scores)),
        'val_r2': (np.mean(r2_scores), np.std(r2_scores)),
        # Test set metrics (average prediction results)
        'test_mse': mse_test,
        'test_rmse': rmse_test,
        'test_mae': mae_test,
        'test_r2': (r2_test, np.std(test_r2_scores)),  # Mean ± standard deviation
        'y_pred_test': y_pred_test_mean
    }


def load_data_groups():
    data_files = {
        'GVAM-Rn': {
            'train': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_train_encoded_GVAM-RN.xlsx',
            'test': r"E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_test_encoded_GVAM-RN.xlsx"
        },
        'VAM-Rn': {
            'train': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_train_encoded_VAM-RN.xlsx',
            'test': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_test_encoded_VAM-RN.xlsx'
        },
        'GVAM': {
            'train': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_train_encoded_RAE.xlsx',
            'test': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_test_encoded_RAE.xlsx'
        },
        'RAE': {
            'train': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_train_encoded_IVAM.xlsx',
            'test': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_test_encoded_IVAM.xlsx'
        },
        'Transformer': {
            'train': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_train_encoded_Transformer.xlsx',
            'test': r'E:\Codes_and_datasets\Dimensionality_reduction_file\5MW-Different_DR_models\X_test_encoded_Transformer.xlsx'
        }
    }

    data_groups = []
    group_names = []
    for group_name, files in data_files.items():
        try:
            X_train = pd.read_excel(files['train'])
            X_test = pd.read_excel(files['test'])
            data_groups.append((X_train, X_test))
            group_names.append(group_name)
            print(f"Loaded {group_name} successfully")
        except Exception as e:
            print(f"Error loading {group_name}: {e}")

    return data_groups, group_names


def plot_comparison_figures(y_true1, y_pred_list1, y_true2, y_pred_list2,
                            titles, colors, target_names, save_path=None, figsize=(16, 12)):
    plt.rcParams.update({
        'font.family': ['Times New Roman', 'serif'],
        'font.serif': ['Times New Roman', 'serif'],
        'font.sans-serif': ['Times New Roman', 'Arial'],
        'mathtext.fontset': 'stix',
        'mathtext.rm': 'Times New Roman',
        'mathtext.it': 'Times New Roman:italic',
        'font.size': 24,
        'axes.labelsize': 28,
        'axes.titlesize': 26,
        'legend.fontsize': 18,
        'xtick.labelsize': 28,
        'ytick.labelsize': 28,
        'figure.titlesize': 26,
        'text.usetex': False,
    })

    fig, axs = plt.subplots(2, 1, figsize=figsize, gridspec_kw={'hspace': 0.5})
    subplot_labels = ['(a)', '(b)']  # Subplot labels retain academic format

    markers = ['^', 's', 'd', 'v', 'o']
    linestyles = ['-', '--', '-.', ':', '--']

    # Upper subplot: DELMt Estimation Comparison
    ax = axs[0]
    index = range(len(y_true1))
    # True value curve: English legend + style
    ax.plot(index, y_true1, 'r-o', label=f'True {target_names[0]}', linewidth=2, markersize=6, alpha=0.7)
    # Estimated curves for each dimensionality reduction method: cycle match method name and style
    for pred, title, color, marker, ls in zip(y_pred_list1, titles, colors, markers, linestyles):
        ax.plot(index, pred, color=color, marker=marker, linestyle=ls,
                label=title, linewidth=2, markersize=6, alpha=0.7)
    # Title and axis labels
    ax.set_title(f'Estimation vs. True Values of {target_names[0]} Using CatBoost-MLP Method')
    ax.set_xlabel('Test Set Sample Index')
    ax.set_ylabel(f'{target_names[0]} (N·m)')
    ax.grid(True, linestyle='--', alpha=0.6)
    # Legend position and font
    legend = ax.legend(loc='lower right', bbox_to_anchor=(1.0, 0.0))
    for text in legend.get_texts():
        text.set_fontfamily(['Times New Roman', 'serif'])
    # Subplot label annotation
    ax.text(0.5, -0.25, subplot_labels[0], transform=ax.transAxes,
            ha='center', va='top', fontsize=24, fontfamily=['Times New Roman', 'serif'])

    # Lower subplot: DELTs Estimation Comparison
    ax = axs[1]
    index = range(len(y_true2))
    # True value curve
    ax.plot(index, y_true2, 'r-o', label=f'True {target_names[1]}', linewidth=2, markersize=6, alpha=0.7)
    # Estimated curves for each dimensionality reduction method
    for pred, title, color, marker, ls in zip(y_pred_list2, titles, colors, markers, linestyles):
        ax.plot(index, pred, color=color, marker=marker, linestyle=ls,
                label=title, linewidth=2, markersize=6, alpha=0.7)
    # English title and axis labels
    ax.set_title(f'Estimation vs. True Values of {target_names[1]} Using CatBoost-MLP Method')
    ax.set_xlabel('Test Set Sample Index')
    ax.set_ylabel(f'{target_names[1]} (N·m)')
    ax.grid(True, linestyle='--', alpha=0.6)
    # Legend
    legend = ax.legend(loc='lower right', bbox_to_anchor=(1.0, 0.0))
    for text in legend.get_texts():
        text.set_fontfamily(['Times New Roman', 'serif'])
    # Subplot label annotation
    ax.text(0.5, -0.25, subplot_labels[1], transform=ax.transAxes,
            ha='center', va='top', fontsize=24, fontfamily=['Times New Roman', 'serif'])

    # Adjust subplot spacing to ensure all elements are fully displayed
    plt.subplots_adjust(left=0.1, right=0.95, top=0.92, bottom=0.1)
    # Save path
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Figure saved to {save_path}")
    plt.show()


def print_evaluation_results(group_names, delmt_results_list, delts_results_list):
    """Output validation and test set evaluation metrics, distinguishing target variables and methods"""
    metrics = ["MSE", "RMSE", "MAE", "R2"]
    # 1. DELMt validation and test set data
    delmt_data = []
    for metric in metrics:
        # Validation set row
        val_row = ["DELMt", f"Val {metric}"]
        # Test set row
        test_row = ["DELMt", f"Test {metric}"]
        for (_, results) in delmt_results_list:
            if metric == "MSE":
                val_val, val_std = results["val_mse"]
                test_val = results["test_mse"]
            elif metric == "RMSE":
                val_val, val_std = results["val_rmse"]
                test_val = results["test_rmse"]
            elif metric == "MAE":
                val_val, val_std = results["val_mae"]
                test_val = results["test_mae"]
            elif metric == "R2":
                val_val, val_std = results["val_r2"]
                test_val, test_std = results["test_r2"]
            # Validation set format: mean ± standard deviation
            val_row.append(f"{val_val:.6g}±{val_std:.6g}")
            # Test set format: mean (R2 with standard deviation)
            if metric == "R2":
                test_row.append(f"{test_val:.6g}±{test_std:.6g}")
            else:
                test_row.append(f"{test_val:.6g}")
        delmt_data.append(val_row)
        delmt_data.append(test_row)

    # 2. DELTs validation and test set data
    delts_data = []
    for metric in metrics:
        val_row = ["DELTs", f"Val {metric}"]
        test_row = ["DELTs", f"Test {metric}"]
        for (_, results) in delts_results_list:
            if metric == "MSE":
                val_val, val_std = results["val_mse"]
                test_val = results["test_mse"]
            elif metric == "RMSE":
                val_val, val_std = results["val_rmse"]
                test_val = results["test_rmse"]
            elif metric == "MAE":
                val_val, val_std = results["val_mae"]
                test_val = results["test_mae"]
            elif metric == "R2":
                val_val, val_std = results["val_r2"]
                test_val, test_std = results["test_r2"]
            val_row.append(f"{val_val:.6g}±{val_std:.6g}")
            if metric == "R2":
                test_row.append(f"{test_val:.6g}±{test_std:.6g}")
            else:
                test_row.append(f"{test_val:.6g}")
        delts_data.append(val_row)
        delts_data.append(test_row)

    # Combine and print table
    all_data = delmt_data + delts_data
    headers = ["Target Variable", "Evaluation Metric"] + group_names
    print("\nEvaluation Metrics Comparison (Validation + Test Set):")
    print(tabulate(
        all_data,
        headers=headers,
        tablefmt="simple_grid",
        colalign=["center"] * len(headers),
        maxcolwidths=[15, 20] + [16] * len(group_names)  # Adapt width for ± standard deviation
    ))


def main():
    # -------------------------- Hyperparameter settings (adapt optimal hyperparameter lists for different dimensionality reduction models) --------------------------
    hyperparameters = {
        # Default methods (GVAM-Rn, VAM-Rn, GVAM) hyperparameters
        'default': {
            'DELMt': {
                'catboost': {
                    'depth': 3,
                    'iterations': 100,
                    'learning_rate': 0.29,
                    'l2_leaf_reg': 5,
                    'border_count': 260,
                    'loss_function': 'MAE'
                },
                'mlp': {
                    'MLP_hidden_sizes': [2025, 512, 128],
                    'dropout_rate': 0.8,
                    'batch_size': 128,
                    'lr': 2e-5,
                    'num_epochs': 20
                }
            },
            'DELTs': {
                'catboost': {
                    'depth': 3,
                    'iterations': 210,
                    'learning_rate': 0.01,
                    'l2_leaf_reg': 2,
                    'border_count': 260,
                    'loss_function': 'RMSE'
                },
                'mlp': {
                    'MLP_hidden_sizes': [2025, 512, 128],
                    'dropout_rate': 0.02,
                    'batch_size': 300,
                    'lr': 2e-6,
                    'num_epochs': 10
                }
            }
        },
        # Separate hyperparameters for RAE method
        'RAE': {
            'DELMt': {
                'catboost': {
                    'depth': 4,
                    'iterations': 150,
                    'learning_rate': 0.25,
                    'l2_leaf_reg': 3,
                    'border_count': 200,
                    'loss_function': 'MAE'
                },
                'mlp': {
                    'MLP_hidden_sizes': [1500, 384, 128],
                    'dropout_rate': 0.8,
                    'batch_size': 64,
                    'lr': 1e-5,
                    'num_epochs': 25
                }
            },
            'DELTs': {
                'catboost': {
                    'depth': 8,
                    'iterations': 250,
                    'learning_rate': 0.08,
                    'l2_leaf_reg': 3,
                    'border_count': 200,
                    'loss_function': 'RMSE'
                },
                'mlp': {
                    'MLP_hidden_sizes': [1500, 384, 128],
                    'dropout_rate': 0.05,
                    'batch_size': 200,
                    'lr': 1e-6,
                    'num_epochs': 15
                }
            }
        },
        # Separate hyperparameters for Transformer method
        'Transformer': {
            'DELMt': {
                'catboost': {
                    'depth': 10,
                    'iterations': 200,
                    'learning_rate': 0.01,
                    'l2_leaf_reg': 2,
                    'border_count': 300,
                    'loss_function': 'MAE'
                },
                'mlp': {
                    'MLP_hidden_sizes': [2024, 512, 256],
                    'dropout_rate': 0.2,
                    'batch_size': 256,
                    'lr': 1e-5,
                    'num_epochs': 50
                }
            },
            'DELTs': {
                'catboost': {
                    'depth': 10,
                    'iterations': 500,
                    'learning_rate': 0.05,
                    'l2_leaf_reg': 1,
                    'border_count': 300,
                    'loss_function': 'RMSE'
                },
                'mlp': {
                    'MLP_hidden_sizes': [2024, 512, 256],
                    'dropout_rate': 0.25,
                    'batch_size': 128,
                    'lr': 0.005,
                    'num_epochs': 50
                }
            }
        }
    }

    # Load target variables
    try:
        print('Loading target variables...')
        targets_train = pd.read_excel(r"E:\Codes_and_datasets\Datasets\48000-Training_data-DEL.xlsx")
        y_DELMt_train = targets_train['DELMt']
        y_DELTs_train = targets_train['DELTs']

        targets_test = pd.read_excel(r"E:\Codes_and_datasets\Datasets\10-Test_data-DEL.xlsx")
        y_DELMt_test = targets_test['DELMt']
        y_DELTs_test = targets_test['DELTs']
        print('Target variables loaded successfully.')
    except Exception as e:
        print(f'Error loading target variables: {e}')
        return

    # Load 5 data groups
    data_groups, group_names = load_data_groups()
    colors = ['blue', 'green', 'brown', 'purple', '#FFA500']

    # Process DELMt task (select hyperparameters based on method)
    print("\nProcessing DELMt...")
    delmt_results_list = []
    delmt_preds = []
    for (X_train, X_test), group_name in zip(data_groups, group_names):
        print(f"\nProcessing {group_name} for DELMt...")
        # Select hyperparameters: use separate params for RAE/Transformer, default otherwise
        if group_name in ['RAE', 'Transformer']:
            cb_params = hyperparameters[group_name]['DELMt']['catboost']
            mlp_params = hyperparameters[group_name]['DELMt']['mlp']
        else:
            cb_params = hyperparameters['default']['DELMt']['catboost']
            mlp_params = hyperparameters['default']['DELMt']['mlp']
        # Train and evaluate
        results = train_and_evaluate(
            X_train, X_test, y_DELMt_train, y_DELMt_test,
            cb_params, mlp_params
        )
        delmt_results_list.append((group_name, results))
        delmt_preds.append(results['y_pred_test'])

    # Process DELTs task (select hyperparameters similarly)
    print("\nProcessing DELTs...")
    delts_results_list = []
    delts_preds = []
    for (X_train, X_test), group_name in zip(data_groups, group_names):
        print(f"\nProcessing {group_name} for DELTs...")
        if group_name in ['RAE', 'Transformer']:
            cb_params = hyperparameters[group_name]['DELTs']['catboost']
            mlp_params = hyperparameters[group_name]['DELTs']['mlp']
        else:
            cb_params = hyperparameters['default']['DELTs']['catboost']
            mlp_params = hyperparameters['default']['DELTs']['mlp']
        results = train_and_evaluate(
            X_train, X_test, y_DELTs_train, y_DELTs_test,
            cb_params, mlp_params
        )
        delts_results_list.append((group_name, results))
        delts_preds.append(results['y_pred_test'])

    # Print validation + test set metrics
    print_evaluation_results(group_names, delmt_results_list, delts_results_list)

    # Plot comparison figures
    plot_comparison_figures(
        y_DELMt_test, delmt_preds,  # DELMt true values and predictions from each method
        y_DELTs_test, delts_preds,  # DELTs true values and predictions from each method
        titles=group_names,  # Dimensionality reduction method names (e.g., GVAM-Rn, Transformer)
        colors=colors,  # Color configuration
        target_names=[r"${\it DEL}_{\rm Mt}$", r"${\it DEL}_{\rm Ts}$"],  # Keep academic format for load symbols
        save_path=r'E:\Codes_and_datasets\pictures\5-DR-methods-for-Estimation.svg'
    )

if __name__ == "__main__":
    main()