import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import logging
import random
import math
import os
from tabulate import tabulate

# Configure logging (only keep key information)
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')

# -------------------------- Core Configuration: Global Font + Fixed Parameters --------------------------
# Font configuration (overridden in subsequent plotting, kept non-conflicting)
plt.rcParams.update({
    'font.family': ['SimHei', 'Microsoft YaHei', 'SimSun', 'FangSong', 'STSong', 'serif'],
    'axes.unicode_minus': False,
    'mathtext.fontset': 'stix',
    'mathtext.default': 'it',
    'font.size': 20,
    'axes.labelsize': 22,
    'axes.titlesize': 26,
    'legend.fontsize': 14,
    'xtick.labelsize': 20,
    'ytick.labelsize': 20,
    'text.usetex': False
})

# Fixed parameter dictionary: each of the 4 methods has exclusive parameters (TFL/DANN/MAML/ITP-MAML)
FIXED_TASK_PARAMS = {
    'common': {
        'seed': 42,
        'hidden_dims': [2024, 512, 128],
        'pth_itp': r'E:\Codes_and_datasets\Model_weights\ITP-MAML.pth',
        'pth_maml': r'E:\Codes_and_datasets\Model_weights\MAML.pth',
        'pth_dann': r'E:\Codes_and_datasets\Model_weights\DANN.pth'
    },
    # 1. TFL Specific Parameters
    'TFL': {
        'DEL_Mt': {
            'num_steps': 3,
            'dropout_rate': 0.8,
            'prelu_init': 0.9,
            'epochs_per_step': 100,
            'lr_feat': 0.0002,
            'lr_out': 0.002,
            'batch_size': 50
        },
        'DEL_Ts': {
            'num_steps': 3,
            'dropout_rate': 0.8,
            'prelu_init': 0.3,
            'epochs_per_step': 50,
            'lr_feat': 0.001,
            'lr_out': 1e-05,
            'batch_size': 30
        },
        'DEL_Rm': {
            'dropout_rate': 0.85,
            'prelu_init': 0.92,
            'batch_size': 50,
            'epochs_per_step': 100,
            'num_steps': 2,
            'lr_feat': 0.002,
            'lr_out': 0.025,
        },
        'DEL_Yb': {
            'dropout_rate': 0.8,
            'prelu_init': 0.92,
            'batch_size': 50,
            'epochs_per_step': 100,
            'num_steps': 2,
            'lr_feat': 0.002,
            'lr_out': 0.025,
        }
    },
    # 2. DANN Specific Parameters
    'DANN': {
        'DEL_Mt': {
            'num_steps': 3,
            'dropout_rate': 0.78,
            'prelu_init': 0.9,
            'epochs_per_step': 100,
            'lr_feat': 0.0002,
            'lr_out': 0.002,
            'batch_size': 50
        },
        'DEL_Ts': {
            'num_steps': 3,
            'dropout_rate': 0.8,
            'prelu_init': 0.3,
            'epochs_per_step': 50,
            'lr_feat': 0.001,
            'lr_out': 1e-05,
            'batch_size': 30
        },
        'DEL_Rm': {
            'dropout_rate': 0.9,
            'prelu_init': 0.92,
            'batch_size': 50,
            'epochs_per_step': 100,
            'num_steps': 2,
            'lr_feat': 0.002,
            'lr_out': 0.025,
        },
        'DEL_Yb': {
            'dropout_rate': 0.8,
            'prelu_init': 0.92,
            'batch_size': 50,
            'epochs_per_step': 100,
            'num_steps': 2,
            'lr_feat': 0.002,
            'lr_out': 0.025,
        }
    },
    # 3. MAML Specific Parameters
    'MAML': {
        'DEL_Mt': {
            'num_steps': 3,
            'dropout_rate': 0.8,
            'prelu_init': 0.9,
            'epochs_per_step': 100,
            'lr_feat': 0.0002,
            'lr_out': 0.002,
            'batch_size': 50
        },
        'DEL_Ts': {
            'num_steps': 3,
            'dropout_rate': 0.5,
            'prelu_init': 0.3,
            'epochs_per_step': 50,
            'lr_feat': 0.001,
            'lr_out': 1e-05,
            'batch_size': 30
        },
        'DEL_Rm': {
            'dropout_rate': 0.84,
            'prelu_init': 0.85,
            'batch_size': 50,
            'epochs_per_step': 100,
            'num_steps': 2,
            'lr_feat': 0.002,
            'lr_out': 0.025,
        },
        'DEL_Yb': {
            'dropout_rate': 0.8,
            'prelu_init': 0.92,
            'batch_size': 50,
            'epochs_per_step': 100,
            'num_steps': 2,
            'lr_feat': 0.002,
            'lr_out': 0.025,
        }
    },
    # 4. ITP-MAML Specific Parameters
    'ITP-MAML': {
        'DEL_Mt': {
            'num_steps': 3,
            'dropout_rate': 0.25,
            'prelu_init': 0.9,
            'epochs_per_step': 100,
            'lr_feat': 0.0002,
            'lr_out': 0.002,
            'batch_size': 50
        },
        'DEL_Ts': {
            'num_steps': 3,
            'dropout_rate': 0.2,
            'prelu_init': 0.3,
            'epochs_per_step': 50,
            'lr_feat': 0.001,
            'lr_out': 1e-05,
            'batch_size': 30
        },
        'DEL_Rm': {
            'dropout_rate': 0.25,
            'prelu_init': 0.9,
            'batch_size': 50,
            'epochs_per_step': 100,
            'num_steps': 2,
            'lr_feat': 0.002,
            'lr_out': 0.025,
        },
        'DEL_Yb': {
            'dropout_rate': 0.2,
            'prelu_init': 0.92,
            'batch_size': 50,
            'epochs_per_step': 100,
            'num_steps': 2,
            'lr_feat': 0.002,
            'lr_out': 0.025,
        }
    }
}

# -------------------------- 1. Global Utility Functions --------------------------
def set_random_seed(seed):
    """Fix all random seeds to ensure 100% reproducibility"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def seed_worker(worker_id):
    """Set random seed for data loader workers"""
    worker_seed = torch.initial_seed() % 2 ** 32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


def create_data_loaders(dataset, batch_size, shuffle=True):
    """Create data loader with fixed seed for reproducibility"""
    generator = torch.Generator().manual_seed(42)  # Fix data loader seed
    return DataLoader(
        dataset, batch_size=batch_size, shuffle=shuffle,
        worker_init_fn=seed_worker, generator=generator
    )


def load_pth_file(file_path):
    """Load pre-trained model parameters"""
    try:
        saved_state_dict = torch.load(file_path, weights_only=True)
        print(f"\n{file_path} Pre-trained parameters preview (first 5):")
        for key, value in list(saved_state_dict.items())[:5]:
            print(f"Key: {key}, Shape: {value.shape}")
        return saved_state_dict
    except FileNotFoundError:
        print(f"‚ö†Ô∏è Pre-trained file not found: {file_path}, using random initialization")
        return None
    except Exception as e:
        print(f"Error loading pre-trained file: {e}")
        return None


def load_data_15mw():
    """Load 1.5MW dataset (directly read independent training/test set files, replacing original slicing logic)"""
    # Training set file paths (specified by user)
    X_path_train = r"E:\Codes_and_datasets\Dimensionality_reduction_file\OP1.5MW_encoded_50_Train.xlsx"
    y_path_train = r"E:\Codes_and_datasets\Datasets\1.5MW\OP1.5MW_targets_50_Train.xlsx"

    # Test set file paths (specified by user)
    X_path_test = r"E:\Codes_and_datasets\Dimensionality_reduction_file\OP1.5MW_encoded_10_Test.xlsx"
    y_path_test = r"E:\Codes_and_datasets\Datasets\1.5MW\OP1.5MW_targets_10_Test.xlsx"

    # Step 1: Check if all files exist
    file_paths = [
        (X_path_train, "Training set features file"),
        (y_path_train, "Training set targets file"),
        (X_path_test, "Test set features file"),
        (y_path_test, "Test set targets file")
    ]
    for path, file_desc in file_paths:
        if not os.path.exists(path):
            raise FileNotFoundError(f"‚ùå {file_desc} does not exist: {path}")

    # Step 2: Load data (reset index to avoid row number interference)
    print("Loading 1.5MW dataset (independent training/test set files)...")
    X_train_df = pd.read_excel(X_path_train).reset_index(drop=True)
    y_train_df = pd.read_excel(y_path_train).reset_index(drop=True)
    X_test_df = pd.read_excel(X_path_test).reset_index(drop=True)
    y_test_df = pd.read_excel(y_path_test).reset_index(drop=True)

    # Step 3: Verify data consistency (matching rows between features and targets in training/test sets)
    if len(X_train_df) != len(y_train_df):
        raise ValueError(f"‚ùå Mismatched rows: Training set features ({len(X_train_df)} rows) vs targets ({len(y_train_df)} rows)")
    if len(X_test_df) != len(y_test_df):
        raise ValueError(f"‚ùå Mismatched rows: Test set features ({len(X_test_df)} rows) vs targets ({len(y_test_df)} rows)")

    # Step 4: Convert to numpy format usable by the model (float32 saves memory)
    X_train = X_train_df.values.astype(np.float32)
    X_test = X_test_df.values.astype(np.float32)

    # Step 5: Extract target variables for each task (ensure shape is (n_samples, 1))
    def get_target_data(df, col_name):
        if col_name not in df.columns:
            raise KeyError(f"‚ùå Column not found in targets file: {col_name} (please check if Excel column names are consistent)")
        return df[col_name].values.astype(np.float32).reshape(-1, 1)

    y_train = {
        "DEL_Mt": get_target_data(y_train_df, 'DELMt'),
        "DEL_Ts": get_target_data(y_train_df, 'DELTs'),
        "DEL_Rm": get_target_data(y_train_df, 'DELRm'),
        "DEL_Yb": get_target_data(y_train_df, 'DELYb')
    }
    y_test_original = {
        "DEL_Mt": get_target_data(y_test_df, 'DELMt'),
        "DEL_Ts": get_target_data(y_test_df, 'DELTs'),
        "DEL_Rm": get_target_data(y_test_df, 'DELRm'),
        "DEL_Yb": get_target_data(y_test_df, 'DELYb')
    }

    # Step 7: Print data loading results (clearly show data information)
    print(f"\n{'=' * 80}")
    print(f"1.5MW Dataset Loading Results:")
    print(f"Training set: {len(X_train_df)} samples (feature dimension: {X_train.shape[1]})")
    print(f"Test set: {len(X_test_df)} samples (feature dimension: {X_test.shape[1]})")

    print(f"{'=' * 80}")
    print(f"\nData Shape Details:")
    print(f"Training set features: {X_train.shape}, Test set features: {X_test.shape}")
    for task in y_train:
        print(f"{task} - Training set: {y_train[task].shape}, Test set: {y_test_original[task].shape}")

    return X_train, y_train, X_test, y_test_original


# -------------------------- 2. Model Definition --------------------------
class ResidualBlockTask(nn.Module):
    def __init__(self, dim, dropout_rate, prelu_init):
        super().__init__()
        self.depthwise = nn.Conv1d(dim, dim, kernel_size=1, groups=dim)
        self.pointwise = nn.Conv1d(dim, dim, kernel_size=1)
        self.se = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Conv1d(dim, dim // 4, 1),
            nn.ReLU(),
            nn.Conv1d(dim // 4, dim, 1),
            nn.Sigmoid()
        )
        self.prelu = nn.PReLU(num_parameters=dim, init=prelu_init)
        self.dropout = nn.Dropout(dropout_rate)
        self.ln = nn.LayerNorm(dim)

    def forward(self, x):
        residual = x
        x = x.unsqueeze(2)
        x = self.depthwise(x)
        x = self.pointwise(x)
        x = x * self.se(x)
        x = x.squeeze(2)
        x = self.ln(x)
        x = self.prelu(x)
        x = self.dropout(x)
        return x + residual  # Residual connection


class MultiTaskModel(nn.Module):
    def __init__(self, input_dim, hidden_dims, dropout_rate, prelu_init):
        super().__init__()
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dims[0]),
            nn.PReLU(num_parameters=hidden_dims[0], init=prelu_init),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dims[0], hidden_dims[1]),
            nn.PReLU(num_parameters=hidden_dims[1], init=prelu_init),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dims[1], hidden_dims[2]),
            nn.PReLU(num_parameters=hidden_dims[2], init=prelu_init),
            nn.Dropout(dropout_rate)
        )
        self.task_classifier_DEL_Mt = nn.Sequential(ResidualBlockTask(hidden_dims[2], dropout_rate, prelu_init),
                                                    nn.Linear(hidden_dims[2], 1))
        self.task_classifier_DEL_Ts = nn.Sequential(ResidualBlockTask(hidden_dims[2], dropout_rate, prelu_init),
                                                    nn.Linear(hidden_dims[2], 1))
        self.task_classifier_DEL_Rm = nn.Sequential(ResidualBlockTask(hidden_dims[2], dropout_rate, prelu_init),
                                                    nn.Linear(hidden_dims[2], 1))
        self.task_classifier_DEL_Yb = nn.Sequential(ResidualBlockTask(hidden_dims[2], dropout_rate, prelu_init),
                                                    nn.Linear(hidden_dims[2], 1))

    def forward(self, x):
        features = self.feature_extractor(x)
        return (
            self.task_classifier_DEL_Mt(features),
            self.task_classifier_DEL_Ts(features),
            self.task_classifier_DEL_Rm(features),
            self.task_classifier_DEL_Yb(features)
        )


# -------------------------- 3. Core Training and Evaluation Functions --------------------------
def load_pretrained_model(model, task_name, pth_path, prelu_init, method_name, current_task):
    """Load pre-trained model parameters - adapted for TFL without transfer (no loading when pth_path is None)"""
    if not pth_path or not os.path.exists(pth_path):
        print(f"‚ö†Ô∏è {method_name} does not load pre-trained parameters (no pth file), using random initialization")
        return model

    saved_dict = load_pth_file(pth_path)
    if saved_dict:
        model_dict = model.state_dict()

        # Create a new pre-trained parameter dictionary to handle key name mismatch
        pretrained_dict = {}

        for key, value in saved_dict.items():
            # Process output_layer of MAML model (output dimension: 2 - dim 0=DELMt, dim 1=DELTs)
            if "output_layer" in key:
                # Define mapping between tasks and MAML output dimensions
                task_dim_map = {
                    "DEL_Mt": 0,  # MAML's output_layer dim 0 corresponds to DELMt
                    "DEL_Ts": 1   # MAML's output_layer dim 1 corresponds to DELTs
                }
                # Only DELMt and DELTs can extract parameters from MAML; skip other tasks (DEL_Rm/DEL_Yb)
                if current_task not in task_dim_map:
                    print(f"‚ö†Ô∏è MAML not trained on {current_task} task, skip loading output_layer parameters for this task")
                    continue

                dim_idx = task_dim_map[current_task]
                if "weight" in key:
                    new_key = f"task_classifier_{current_task}.1.weight"
                    # Slice: extract dim_idx from [2,128] to get [1,128] (match single output shape)
                    pretrained_dict[new_key] = value[dim_idx:dim_idx + 1, :]
                elif "bias" in key:
                    new_key = f"task_classifier_{current_task}.1.bias"
                    # Slice: extract dim_idx from [2] to get [1] (match single output shape)
                    pretrained_dict[new_key] = value[dim_idx:dim_idx + 1]
                else:
                    continue
                print(f"Map MAML parameter: {key}[{dim_idx}] -> {new_key} (Shape: {pretrained_dict[new_key].shape})")

            # Process feature extractor parameters
            elif "feature_extractor" in key:
                pretrained_dict[key] = value

            # Process other possible key name formats
            elif "task_classifier" in key:
                pretrained_dict[key] = value
            else:
                if key.startswith("0.") or key.startswith("1.") or key.startswith("2."):
                    new_key = f"feature_extractor.{key}"
                    pretrained_dict[new_key] = value
                    print(f"Map sequence parameter: {key} -> {new_key}")

        # Filter keys that exist in the current model
        filtered_pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}

        if not filtered_pretrained_dict:
            print(f"‚ö†Ô∏è Pre-trained parameters do not match model structure, using random initialization")
            return model

        # Update model parameters
        model_dict.update(filtered_pretrained_dict)

        try:
            model.load_state_dict(model_dict, strict=False)
            print(f"‚úÖ Successfully loaded {method_name} pre-trained parameters for {task_name} ({len(filtered_pretrained_dict)} parameters)")

            # Reset PReLU parameters
            for module in model.modules():
                if isinstance(module, nn.PReLU):
                    module.weight.data.fill_(prelu_init)

        except Exception as e:
            print(f"‚ùå Failed to load pre-trained parameters: {e}, using random initialization")

    return model


def progressive_fine_tune(model, train_loader, optimizer, criterion, task_params, method_name):
    """Progressive fine-tuning (fixed parameter training)"""
    set_random_seed(task_params['common']['seed'])
    num_layers = len(model.feature_extractor) // 3
    num_steps = task_params['task_specific']['num_steps']

    for step in range(num_steps):
        # Gradually increase data volume
        subset_size = int(len(train_loader.dataset) * (step + 1) / num_steps)
        subset_indices = torch.randperm(len(train_loader.dataset))[:subset_size]
        subset_dataset = torch.utils.data.Subset(train_loader.dataset, subset_indices)
        subset_loader = DataLoader(
            subset_dataset,
            batch_size=task_params['task_specific']['batch_size'],
            shuffle=True
        )

        # Gradually unfreeze layers (unified logic for all methods, parameter differences reflected via task_params)
        num_unfreeze = (step + 1) * (num_layers // num_steps)

        # Set parameter gradients
        for i, layer in enumerate(model.feature_extractor):
            for param in layer.parameters():
                # Each 3 layers form a block (Linear+PReLU+Dropout)
                block_idx = i // 3
                param.requires_grad = (block_idx < num_unfreeze)

        # Fine-tuning training
        for epoch in range(task_params['task_specific']['epochs_per_step']):
            model.train()
            total_loss = 0
            batch_count = 0

            for x, y in subset_loader:
                y_preds = model(x)
                y_pred = y_preds[task_params['current_task_idx']]
                loss = criterion(y_pred, y)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                total_loss += loss.item()
                batch_count += 1

    return model


def evaluate_with_multiple_methods(X_train, y_train, X_test, y_test_original):
    """Train and evaluate using four methods (each method uses exclusive parameters)"""
    print(f"\n{'=' * 100}")
    print(f"{'=' * 100}")

    # Fix global random seed
    global_seed = FIXED_TASK_PARAMS['common']['seed']
    set_random_seed(global_seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    print(f"Global random seed: {global_seed} (ensures result reproducibility)")

    # Method order: [TFL, DANN, MAML, ITP-MAML]
    tasks = ["DEL_Mt", "DEL_Ts", "DEL_Rm", "DEL_Yb"]
    methods = ["TFL", "DANN", "MAML", "ITP-MAML"]
    all_results = {task: {method: None for method in methods} for task in tasks}
    img_dir = r"E:\Codes_and_datasets\pictures"
    os.makedirs(img_dir, exist_ok=True)

    # Method configuration: pth path mapping (TFL does not load pth)
    method_configs = {
        "TFL": {"pth_key": None, "description": "No transfer learning (fine-tuning only)"},
        "DANN": {"pth_key": "pth_dann", "description": "DANN transfer learning"},
        "MAML": {"pth_key": "pth_maml", "description": "MAML transfer learning"},
        "ITP-MAML": {"pth_key": "pth_itp", "description": "ITP-MAML transfer learning"}
    }

    # Target variable plotting information
    target_info_map = {
        "DEL_Mt": {"plot_name": "$\\it{DEL}_{\\text{Mt}}$", "label": "$\\it{DEL}_{\\text{Mt}}$ (N¬∑m)"},
        "DEL_Ts": {"plot_name": "$\\it{DEL}_{\\text{Ts}}$", "label": "$\\it{DEL}_{\\text{Ts}}$ (N¬∑m)"},
        "DEL_Rm": {"plot_name": "$\\it{DEL}_{\\text{Rm}}$", "label": "$\\it{DEL}_{\\text{Rm}}$ (N¬∑m)"},
        "DEL_Yb": {"plot_name": "$\\it{DEL}_{\\text{Yb}}$", "label": "$\\it{DEL}_{\\text{Yb}}$ (N¬∑m)"}
    }
    target_positions = [(0, 0), (0, 1), (1, 0), (1, 1)]  # 2x2 subplot positions

    # Print summary of exclusive parameters for 4 methods
    print(f"\n{'=' * 100}")
    print(f"Summary of Specific Parameters for 4 Methods (1.5MW Dataset)")
    print(f"{'=' * 100}")
    for method in methods:
        print(f"\n[{'=' * 5} {method} Specific Parameters {'=' * 5}]")
        for task in tasks:
            print(f"\n  {task}:")
            for key, value in FIXED_TASK_PARAMS[method][task].items():
                print(f"    {key}: {value}")

    # Train and evaluate each task for each method (each method loads its own exclusive parameters)
    for method_name in methods:
        print(f"\n{'#' * 80}")
        print(f"Starting {method_name} Method Evaluation (using specific parameters)")
        print(f"{'#' * 80}")

        for task_idx, current_task in enumerate(tasks):
            print(f"\nStarting {current_task} training ({method_name})")

            # Core modification: each method loads its own exclusive parameters
            task_specific_params = FIXED_TASK_PARAMS[method_name][current_task]
            print(f"‚ö†Ô∏è {method_name} - {current_task} using specific parameters: {task_specific_params}")

            task_params = {
                'common': FIXED_TASK_PARAMS['common'],
                'task_specific': task_specific_params,
                'current_task': current_task,
                'current_task_idx': task_idx
            }

            # Data standardization (independent standardization for each task to ensure consistency)
            scaler_X = StandardScaler()
            X_train_scaled = scaler_X.fit_transform(X_train)
            X_test_scaled = scaler_X.transform(X_test)

            scaler_y = StandardScaler()
            y_train_scaled = scaler_y.fit_transform(y_train[current_task])
            y_test_scaled = scaler_y.transform(y_test_original[current_task])

            # Build datasets
            train_dataset = TensorDataset(
                torch.tensor(X_train_scaled, dtype=torch.float32),
                torch.tensor(y_train_scaled, dtype=torch.float32)
            )
            test_dataset = TensorDataset(
                torch.tensor(X_test_scaled, dtype=torch.float32),
                torch.tensor(y_test_scaled, dtype=torch.float32)
            )

            # Create data loaders (fixed seed)
            train_loader = create_data_loaders(train_dataset, batch_size=task_specific_params['batch_size'])
            test_loader = create_data_loaders(test_dataset, batch_size=10, shuffle=False)

            # Initialize model (fixed seed to ensure consistent initialization)
            set_random_seed(global_seed + task_idx + methods.index(method_name) * 10)
            model = MultiTaskModel(
                input_dim=X_train.shape[1],
                hidden_dims=FIXED_TASK_PARAMS['common']['hidden_dims'],
                dropout_rate=task_specific_params['dropout_rate'],
                prelu_init=task_specific_params['prelu_init']
            ).to(device)

            # Load pre-trained parameters: match pth path by method (TFL has no pth)
            pth_key = method_configs[method_name]['pth_key']
            pth_path = FIXED_TASK_PARAMS['common'][pth_key] if pth_key is not None else None
            model = load_pretrained_model(
                model, current_task, pth_path,
                task_specific_params['prelu_init'], method_name, current_task
            )

            # Configure optimizer (use exclusive learning rate of current method)
            feat_params = []
            out_params = []
            for name, param in model.named_parameters():
                if "feature_extractor" in name:
                    feat_params.append(param)
                elif f"task_classifier_{current_task}" in name:
                    out_params.append(param)

            optimizer = optim.AdamW([
                {'params': feat_params, 'lr': task_specific_params['lr_feat'], 'weight_decay': 0.01},
                {'params': out_params, 'lr': task_specific_params['lr_out'], 'weight_decay': 0.01}
            ])
            criterion = nn.SmoothL1Loss()

            # Train model
            model = progressive_fine_tune(model, train_loader, optimizer, criterion, task_params, method_name)

            # Test and evaluate
            model.eval()
            y_pred_scaled = []
            y_true_scaled = []
            with torch.no_grad():
                for x, y in test_loader:
                    x, y = x.to(device), y.to(device)
                    y_preds = model(x)
                    y_pred = y_preds[task_idx]
                    y_pred_scaled.extend(y_pred.cpu().numpy())
                    y_true_scaled.extend(y.cpu().numpy())

            # Inverse standardization and metric calculation
            y_pred = scaler_y.inverse_transform(np.array(y_pred_scaled))
            y_true = scaler_y.inverse_transform(np.array(y_true_scaled))
            mse = mean_squared_error(y_true, y_pred)
            metrics = {
                "MSE": mse,
                "RMSE": math.sqrt(mse),
                "MAE": mean_absolute_error(y_true, y_pred),
                "R2": 1 - (np.sum((y_true - y_pred) ** 2) /
                           (np.sum((y_true - np.mean(y_true)) ** 2) + 1e-10))
            }
            all_results[current_task][method_name] = (y_pred, metrics)
            print(f"{method_name} - {current_task} evaluation completed, R2: {metrics['R2']:.6f}")

    # -------------------------- Plotting Code (keep original style) --------------------------
    plt.rcParams.update({
        'font.family': 'Times New Roman',
        'mathtext.fontset': 'stix',
        'font.size': 36,
        'axes.labelsize': 36,
        'axes.titlesize': 36,
        'legend.fontsize': 32,
        'xtick.labelsize': 48,
        'ytick.labelsize': 48,
        'text.usetex': False,
        'axes.unicode_minus': False,
    })

    fig, axs = plt.subplots(
        2, 2,
        figsize=(34, 24),
        gridspec_kw={'hspace': 0.4, 'wspace': 0.25}
    )
    subplot_labels = ['(a)', '(b)', '(c)', '(d)']

    method_order = ["TFL", "DANN", "MAML", "ITP-MAML"]
    colors = ['gray', 'orange', 'green', 'blue']
    markers = ['s', 'o', 'd', '^']
    linestyles = ['--', ':', '--', '-']

    for idx, (target, (row, col)) in enumerate(zip(tasks, target_positions)):
        ax = axs[row, col]
        target_info = target_info_map[target]
        y_true = y_test_original[target].flatten()
        x_idx = range(len(y_true))

        # Plot true values
        ax.plot(x_idx, y_true, color='red', label=f'True {target_info["plot_name"]}',
                marker='o', alpha=0.7, linewidth=3, markersize=8)

        # Plot predictions of four methods
        for j, method in enumerate(method_order):
            y_pred = all_results[target][method][0].flatten()
            ax.plot(x_idx, y_pred, color=colors[j], label=f'{method} {target_info["plot_name"]}',
                    marker=markers[j], linestyle=linestyles[j], alpha=0.7, linewidth=3, markersize=8)

        # Subplot configuration
        ax.set_title(f'{target_info["plot_name"]} Estimation Comparison-1.5MW', fontsize=46)
        ax.set_xlabel('Number of test sets', fontsize=44)
        ax.set_ylabel(target_info["label"], fontsize=42)
        ax.legend(loc='upper right', fontsize=34)
        ax.grid(True, linestyle='--', alpha=0.6, linewidth=2)

        # Scientific notation
        if idx in [1, 3]:
            ax.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))
            ax.yaxis.get_offset_text().set_fontsize(44)

        # Subplot label
        ax.text(
            0.5, -0.17,
            subplot_labels[idx],
            transform=ax.transAxes,
            fontsize=34,
            ha='center',
            va='top'
        )

    plt.subplots_adjust(left=0.07, right=0.93, top=0.95, bottom=0.08)
    save_path = os.path.join(img_dir, f"4_Transfer_Comparisons-1.5MW.svg")
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.show()
    plt.close()
    print(f"\nComprehensive comparison figure saved to: {save_path}")

    return all_results


# -------------------------- 4. Result Printing Function --------------------------
def print_results_tables(results):
    """Print final result tables (order synchronized as [TFL, DANN, MAML, ITP-MAML])"""
    print(f"\n{'=' * 100}")
    print(f"Final Experiment Results Summary (1.5MW Dataset - 4 Methods Comparison)")
    print(f"{'=' * 100}")

    tasks = ["DEL_Mt", "DEL_Ts", "DEL_Rm", "DEL_Yb"]
    methods = ["TFL", "DANN", "MAML", "ITP-MAML"]

    for task in tasks:
        print(f"\n[Task: {task}]")
        table_data = []
        headers = ["Evaluation Metric"] + methods

        for metric in ["MSE", "RMSE", "MAE", "R2"]:
            row = [metric]
            for method in methods:
                if results[task][method] is not None:
                    value = results[task][method][1][metric]
                    row.append(f"{value:.6g}")
                else:
                    row.append("N/A")
            table_data.append(row)

        print(tabulate(table_data, headers=headers, tablefmt="simple_grid", colalign=["center"] * 5))


# -------------------------- 5. Main Function --------------------------
if __name__ == "__main__":
    # Step 1: Fix global random seed
    set_random_seed(FIXED_TASK_PARAMS['common']['seed'])

    # Step 2: Load 1.5MW dataset
    X_train, y_train, X_test, y_test = load_data_15mw()

    # Step 3: Evaluate using four methods (each method uses exclusive parameters)
    final_results = evaluate_with_multiple_methods(
        X_train=X_train,
        y_train=y_train,
        X_test=X_test,
        y_test_original=y_test,
    )

    # Step 4: Print result tables
    print_results_tables(final_results)

    # Step 5: Output completion information
    print(f"\n{'=' * 100}")
    print(f"üéâ 1.5MW Dataset - 4 Methods Comparison Completed!")
    print(f"{'=' * 100}")
    print(f"Key Outputs:")
    print(f"1. Comprehensive Comparison Figure: E:\\Codes_and_datasets\\pictures\\4_Transfer_Comparisons-1.5MW.svg")  # Match actual saved SVG filename
    print(f"2. Used Parameters: Each of the 4 methods has exclusive parameters, printed at the start of execution")
    print(f"3. Result Reproducibility: Global seed fixed to {FIXED_TASK_PARAMS['common']['seed']}, consistent results across runs")
    print(f"4. Comparison Methods (Order): TFL (No transfer learning), DANN, MAML, ITP-MAML")